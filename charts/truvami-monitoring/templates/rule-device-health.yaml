{{- if .Values.alerts.deviceHealth.enabled }}
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    prometheus: kube-prometheus-stack-prometheus
    role: alert-rules
  name: truvami-device-health
spec:
  groups:
    - name: truvami-device-health
      rules:
        - alert: TruvamiDevicePayloadDecodingFailures
          annotations:
            description: >-
              **What's happening:** Device {{ "{{" }} $labels.devEui }} on port {{ "{{" }} $labels.port }} is experiencing high payload decoding failures (>0.1 failures/sec over 5 minutes).

              **Why this occurred:** The system tracks decoding failures using rate(truvami_failed_to_decode_payload_count[5m])
              which measures how often received device payloads cannot be properly decoded. Common causes include:
              - Device firmware changes affecting payload format
              - Corrupted or incomplete data transmission
              - Decoder configuration mismatch with device version
              - Device hardware malfunction affecting data encoding
              - Network interference causing data corruption
              - Device battery issues affecting transmission quality

              **What to do:**
              1. Check device firmware version and decoder compatibility
              2. Verify device hardware health and battery status
              3. Review recent decoder configuration changes
              4. Check network signal quality (RSSI/SNR) for this device
              5. Examine raw payload data for corruption patterns
              6. Consider device replacement if hardware failure suspected
              7. Update decoder if device firmware was recently changed
            summary: >-
              High Truvami device payload decoding failure rate (>0.1/sec over 5min)
          expr: >-
            rate(truvami_failed_to_decode_payload_count[5m]) > 0.1
          for: 2m
          labels:
            namespace: {{ .Release.Namespace }}
            severity: major
            node: "{{ "{{" }} $labels.devEui }}"
            service: truvami-device
            component: decoder
            {{- with .Values.alertLabels }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
        - alert: TruvamiDeviceHighBufferLevel
          annotations:
            description: >-
              Device {{ "{{" }} $labels.devEui }} (customer: {{ "{{" }} $labels.customer }}) has high buffer level: {{ "{{" }} $value }} items (max ~1000).
            summary: >-
              Truvami device buffer level high
          expr: >-
            truvami_device_buffer_level > 800
          for: 5m
          labels:
            namespace: {{ .Release.Namespace }}
            severity: minor
            node: "{{ "{{" }} $labels.devEui }}"
            service: truvami-device
            component: buffer
            {{- with .Values.alertLabels }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
        - alert: TruvamiDeviceFrequentResets
          annotations:
            description: >-
              Device {{ "{{" }} $labels.devEui }} (customer: {{ "{{" }} $labels.customer }}) is resetting frequently due to {{ "{{" }} $labels.reason }}.
            summary: >-
              Truvami device experiencing frequent resets
          expr: >-
            rate(truvami_device_reset_count[1h]) > 0.1
          for: 5m
          labels:
            namespace: {{ .Release.Namespace }}
            severity: major
            node: "{{ "{{" }} $labels.devEui }}"
            service: truvami-device
            component: system
            {{- with .Values.alertLabels }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
        - alert: TruvamiDeviceMultiNetworkProvisioning
          annotations:
            description: >-
              **What's happening:** Device {{ "{{" }} $labels.devEui }} has been detected transmitting on multiple LoRa networks over the past 7 days.

              **Why this occurred:** The query detects devices that have uplinks on both standard gateway IDs (8-character hex format)
              and non-standard gateway IDs within a 7-day window. This indicates the device may be switching between different
              LoRa network configurations with every reset, creating unpredictable network behavior.

              Standard networks use 8-character hexadecimal gateway IDs (e.g., "12AB34CD"), while other networks may use
              different ID formats. When a device transmits on both types, it suggests dual provisioning or network switching.

              **Expected behavior after network migration:** If this alert triggered due to an intentional network change,
              it will automatically clear after 7 days when the old network data expires from the monitoring window.

              **What to do:**
              1. **If network change was intentional** - Wait for alert to auto-clear in 7 days, no action needed
              2. **If unintentional** - Verify device provisioning and check if accidentally provisioned on multiple networks
              3. **Review network configuration** - Ensure device is configured for single network operation
              4. **Check device firmware** - Verify firmware isn't causing network switching behavior
              5. **Monitor device resets** - Correlate with reset patterns to identify switching triggers
              6. **Update network credentials** - Remove device from unintended networks if dual-provisioned
              7. **Contact customer** to verify intended network configuration
              8. **Document network assignment** to prevent future multi-provisioning
            summary: >-
              Truvami device detected on multiple LoRa networks (auto-clears in 7d after network migration)
          expr: >-
            (
              sum by (devEui) (
                count_over_time(truvami_gateway_uplink_rssi{gatewayId=~"^[0-9A-Fa-f]{8}$"}[7d])
              ) > 0
            )
            and on (devEui)
            (
              sum by (devEui) (
                count_over_time(truvami_gateway_uplink_rssi{gatewayId!~"^[0-9A-Fa-f]{8}$"}[7d])
              ) > 0
            )
          for: 10m
          labels:
            namespace: {{ .Release.Namespace }}
            severity: major
            node: "{{ "{{" }} $labels.devEui }}"
            service: truvami-device
            component: network
            {{- with .Values.alertLabels }}
            {{- toYaml . | nindent 12 }}
            {{- end }}

        {{- if .Values.alerts.deviceHealth.excessiveUplinks.enabled }}
        - alert: TruvamiDeviceExcessiveUplinks
          annotations:
            description: >-
              **What's happening:** Device {{ "{{" }} $labels.devEui }} (customer: {{ "{{" }} $labels.customer }}) has sent {{ "{{" }} $value }} uplinks in the past 24 hours, exceeding the {{ .Values.alerts.deviceHealth.excessiveUplinks.threshold }}-uplink daily limit.

              **Device Details:**
              - Device EUI: {{ "{{" }} $labels.devEui }}
              - Customer: {{ "{{" }} $labels.customer }}
              - Daily Uplinks: {{ "{{" }} $value }}
              - Threshold: > {{ .Values.alerts.deviceHealth.excessiveUplinks.threshold }}
              - Service: {{ "{{" }} $labels.job }}
              - Instance: {{ "{{" }} $labels.instance }}

              **Why this occurred:** The device is transmitting far more frequently than expected. With >240 uplinks per day,
              the device is averaging more than one uplink every 6 minutes (24h/240 = 6min intervals), which is excessive
              for most IoT applications and may indicate:

              **Root causes:**
              - **Sensor malfunction** triggering continuous alerts or readings
              - **Configuration error** with extremely frequent transmission intervals
              - **Stuck device firmware** in continuous transmission loop
              - **Environmental triggers** causing constant sensor activation
              - **Testing/debugging mode** accidentally left enabled
              - **Multiple applications** or sensors sharing same device
              - **Network issues** causing excessive retransmissions

              **Impact:**
              - **Severely reduced battery life** - device may drain battery 10x faster
              - **Network congestion** affecting other devices in the area
              - **Higher data costs** and increased infrastructure load
              - **Potential duty cycle violations** approaching LoRaWAN limits
              - **Poor data quality** from over-sampling sensors
              - **Customer service degradation** due to battery replacement needs

              **What to do:**
              1. **Contact customer immediately** {{ "{{" }} $labels.customer }} - this requires attention
              2. **Review device configuration** - check transmission intervals and triggers
              3. **Verify sensor operation** - ensure sensors aren't malfunctioning
              4. **Check for firmware issues** - device may be stuck in test mode
              5. **Analyze uplink patterns** - identify if bursts or continuous transmission
              6. **Monitor battery status** - check for accelerated battery drain
              7. **Compare with similar devices** - verify if isolated or widespread issue
              8. **Consider temporary throttling** if device cannot be reconfigured remotely
              9. **Plan immediate intervention** - may need site visit for reconfiguration
            summary: >-
              {{ "{{" }} $labels.devEui }} excessive daily uplinks: {{ "{{" }} $value }} (threshold: >{{ .Values.alerts.deviceHealth.excessiveUplinks.threshold }})
          expr: >-
            increase(truvami_device_uplink_count[24h]) > {{ .Values.alerts.deviceHealth.excessiveUplinks.threshold }}
          for: {{ .Values.alerts.deviceHealth.excessiveUplinks.duration }}
          labels:
            namespace: {{ .Release.Namespace }}
            severity: {{ .Values.alerts.deviceHealth.excessiveUplinks.severity }}
            node: "{{ "{{" }} $labels.devEui }}"
            service: truvami-device
            component: uplink-frequency
            {{- with .Values.alertLabels }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
        {{- end }}
{{- end }}
