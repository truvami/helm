{{- if .Values.alerts.serviceHealth.enabled }}
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    prometheus: kube-prometheus-stack-prometheus
    role: alert-rules
  name: truvami-service-health
spec:
  groups:
    - name: truvami-service-health
      rules:
        {{- if .Values.alerts.serviceHealth.bridgeDown.enabled }}
        - alert: TruvamiBridgeDown
          annotations:
            description: >-
              **What's happening:** Truvami Bridge instance {{ "{{" }} $labels.instance }} is completely down and unresponsive for over 1 minute. CRITICAL SERVICE FAILURE.

              **Why this occurred:** The system monitors service availability using up{job="truvami-bridge"} == 0
              which indicates the service failed health checks. Truvami Bridge is critical infrastructure that processes all device data. Failure causes include:
              - Service crash or unexpected termination
              - System resource exhaustion (out of memory, CPU overload)
              - Database connectivity failure preventing startup
              - Configuration errors or missing dependencies
              - Network connectivity issues
              - Host system failure or maintenance

              **Business Impact:**
              - **COMPLETE SERVICE OUTAGE:** No device data processing
              - All device communications blocked
              - Real-time alerts and monitoring stopped
              - Customer data collection halted
              - API services may be affected

              **What to do IMMEDIATELY:**
              1. **ESCALATE TO ON-CALL IMMEDIATELY** - this is a P1 incident
              2. **Check service status** and restart if possible
              3. **Verify system resources** and host health
              4. **Check database connectivity** and dependencies
              5. **Review service logs** for crash details
              6. **Prepare customer communications** about service impact
              7. **Monitor for data loss** during outage period
            summary: >-
              Truvami Bridge is down - CRITICAL SERVICE OUTAGE
          expr: >-
            up{job="truvami-bridge"} == 0
          for: {{ .Values.alerts.serviceHealth.bridgeDown.duration }}
          labels:
            namespace: {{ .Release.Namespace }}
            severity: {{ .Values.alerts.serviceHealth.bridgeDown.severity }}
            node: truvami-bridge
            service: truvami-bridge
            {{- with .Values.alertLabels }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
        {{- end }}
        {{- if .Values.alerts.serviceHealth.bridgeHighErrorRate.enabled }}
        - alert: TruvamiBridgeHighErrorRate
          annotations:
            description: >-
              High error rate detected over the last 5 minutes.
            summary: >-
              High error rate in Truvami Bridge (>{{ .Values.alerts.serviceHealth.bridgeHighErrorRate.threshold }} errors/sec over 5min, alert after {{ .Values.alerts.serviceHealth.bridgeHighErrorRate.duration }})
          expr: >-
            (
              rate(truvami_failed_to_decode_payload_count[5m]) +
              rate(truvami_failed_to_create_uplink_through_grpc_count[5m]) +
              rate(truvami_failed_to_fetch_device_metadata_count[5m])
            ) > {{ .Values.alerts.serviceHealth.bridgeHighErrorRate.threshold }}
          for: {{ .Values.alerts.serviceHealth.bridgeHighErrorRate.duration }}
          labels:
            namespace: {{ .Release.Namespace }}
            severity: {{ .Values.alerts.serviceHealth.bridgeHighErrorRate.severity }}
            node: truvami-bridge
            service: truvami-bridge
            {{- with .Values.alertLabels }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
        {{- end }}
{{- end }}
